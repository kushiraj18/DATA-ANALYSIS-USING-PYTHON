{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMZ4Pnq3R9orlPfF9asaUG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kushiraj18/DATA-ANALYSIS-USING-PYTHON/blob/main/2203A52030_DAUP_LAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iz4_vWyI7lOl",
        "outputId": "273cd547-e1bf-465d-b15b-8e6a634e2cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Accuracy  Precision    Recall    FPR       FNR\n",
            "Logistic Regression  0.942308   0.983333  0.921875  0.025  0.078125\n",
            "Decision Tree        0.980769   1.000000  0.968750  0.000  0.031250\n",
            "Random Forest        0.980769   0.984375  0.984375  0.025  0.015625\n",
            "SVM                  0.980769   0.984375  0.984375  0.025  0.015625\n",
            "KNN                  0.932692   0.983051  0.906250  0.025  0.093750\n",
            "Gradient Boosting    0.990385   1.000000  0.984375  0.000  0.015625\n",
            "Model with lowest FNR (Type II Error): Random Forest\n",
            "Z-Test for mean age difference: Z-Statistic = 1.4810358680954627, P-Value = 0.18603116427333352\n",
            "Z-Test for FNR (SVM vs. KNN): Z-Statistic = -2.5151608424234704, P-Value = 0.011897809031118811\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from scipy.stats import norm, ttest_ind\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('/content/diabetes_data_upload.csv')\n",
        "\n",
        "# Preprocessing (Encoding categorical variables if necessary)\n",
        "data = pd.get_dummies(data, drop_first=True)\n",
        "\n",
        "# Split dataset into features and labels\n",
        "X = data.drop(columns=['class_Positive'])\n",
        "y = data['class_Positive']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "    fpr = fp / (fp + tn)\n",
        "    fnr = fn / (fn + tp)\n",
        "    results[name] = {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'FPR': fpr, 'FNR': fnr}\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results).T\n",
        "print(results_df)\n",
        "\n",
        "# Identify model with lowest FNR\n",
        "best_model_fnr = results_df['FNR'].idxmin()\n",
        "print(f'Model with lowest FNR (Type II Error): {best_model_fnr}')\n",
        "\n",
        "# Z-Test: Mean age of correctly classified vs. misclassified diabetic patients\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log = log_reg.predict(X_test)\n",
        "misclassified = X_test[y_test != y_pred_log]\n",
        "correctly_classified = X_test[y_test == y_pred_log]\n",
        "\n",
        "age_misclassified = misclassified[:, 0]\n",
        "age_correct = correctly_classified[:, 0]\n",
        "\n",
        "z_stat, p_value = ttest_ind(age_correct, age_misclassified, equal_var=False)\n",
        "print(f'Z-Test for mean age difference: Z-Statistic = {z_stat}, P-Value = {p_value}')\n",
        "\n",
        "# Check if FPR for Random Forest is > 20%\n",
        "rf_fpr = results_df.loc['Random Forest', 'FPR']\n",
        "if rf_fpr > 0.2:\n",
        "    pop_mean = 0.2\n",
        "    n = len(y_test)\n",
        "    se = np.sqrt((pop_mean * (1 - pop_mean)) / n)\n",
        "    z_stat_fpr = (rf_fpr - pop_mean) / se\n",
        "    p_value_fpr = 2 * (1 - norm.cdf(abs(z_stat_fpr)))\n",
        "    print(f'Z-Test for FPR > 20%: Z-Statistic = {z_stat_fpr}, P-Value = {p_value_fpr}')\n",
        "\n",
        "# Compare FNRs of SVM, KNN, and Logistic Regression\n",
        "fnr_svm = results_df.loc['SVM', 'FNR']\n",
        "fnr_knn = results_df.loc['KNN', 'FNR']\n",
        "n_svm = y_test.shape[0]\n",
        "n_knn = y_test.shape[0]\n",
        "se_fnr = np.sqrt((fnr_svm * (1 - fnr_svm) / n_svm) + (fnr_knn * (1 - fnr_knn) / n_knn))\n",
        "z_stat_fnr = (fnr_svm - fnr_knn) / se_fnr\n",
        "p_value_fnr = 2 * (1 - norm.cdf(abs(z_stat_fnr)))\n",
        "print(f'Z-Test for FNR (SVM vs. KNN): Z-Statistic = {z_stat_fnr}, P-Value = {p_value_fnr}')"
      ]
    }
  ]
}